{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022.1.4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqkRST8o5yht85y1w2Ys7Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZhiYu-2002/copy-of-endonet-2022.1.4/blob/main/2022_1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "jUx8RuUHoW0u",
        "outputId": "82278889-ed98-48a6-92ad-2e5b0262a7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Processing dataset 0... "
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fe92336c3f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mlabelPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/Shareddrives/Surgery Video Research Team/Frames/cholec80/TrainingDataset_sub/trainingData\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meachDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_lables.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_h5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasetPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabelPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-fe92336c3f05>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, h5file_path, annotation_file, transform)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mdataset_h5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Frame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/Shareddrives/Surgery Video Research Team/Frames/cholec80/TrainingDataset_sub/trainingData0.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import io\n",
        "import cv2\n",
        "import h5py\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import output\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class dataset_h5(Dataset):\n",
        "    def __init__(self, h5file_path, annotation_file, transform):\n",
        "        self.h5file = h5py.File(h5file_path, 'r')        \n",
        "        self.annotations = pd.read_csv(annotation_file, index_col='Frame')\n",
        "        self.transform = transform\n",
        "        self.key = list(self.h5file.keys())\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.key)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_id = self.key[index]\n",
        "        img = Image.open(io.BytesIO(np.array(self.h5file[img_id]))) # read the image from h5 file data\n",
        "        y_label = torch.tensor(self.annotations.loc[img_id][0])\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return (img, y_label)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "t = time.time()\n",
        "\n",
        "trainingLoaderSet = []\n",
        "testingLoaderSet = []\n",
        "\n",
        "for eachDataset in range(8):\n",
        "\n",
        "  print(\"Processing dataset %d... \" %(eachDataset), end='')\n",
        "  # Load training dataset\n",
        "  datasetPath = \"/content/drive/Shareddrives/Surgery Video Research Team/Frames/cholec80/TrainingDataset_sub/trainingData\"+str(eachDataset)+'.hdf5'\n",
        "  labelPath = \"/content/drive/Shareddrives/Surgery Video Research Team/Frames/cholec80/TrainingDataset_sub/trainingData\"+str(eachDataset)+\"_lables.txt\"\n",
        "\n",
        "  train_data = dataset_h5(h5file_path=datasetPath, annotation_file=labelPath, transform=transform)\n",
        "  trainloader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=True, num_workers=1)\n",
        "\n",
        "  trainingLoaderSet.append(trainloader)\n",
        "\n",
        "  # Load testing dataset\n",
        "  datasetPath = \"/content/drive/Shareddrives/Surgery Video Research Team/Frames/cholec80/TestingDataset_sub/testingData\"+str(eachDataset)+'.hdf5'\n",
        "  labelPath = \"/content/drive/Shareddrives/Surgery Video Research Team/Frames/cholec80/TestingDataset_sub/testingData\"+str(eachDataset)+\"_lables.txt\"\n",
        "\n",
        "  test_data = dataset_h5(h5file_path=datasetPath, annotation_file=labelPath, transform=transform)\n",
        "  testloader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=True, num_workers=1)\n",
        "\n",
        "  testingLoaderSet.append(testloader)\n",
        "\n",
        "  print(\"Finish!\")\n",
        "print(\"Load all the dataset costs %d minutes %d seconds\"%((time.time()-t)/60, (time.time()-t)%60))\n",
        "\n",
        "valLoaderSet = testingLoaderSet[0:2]\n",
        "\n",
        "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
        "\n",
        "AlexNet_model.eval()\n",
        "\n",
        "AlexNet_model.classifier[6] = nn.Linear(4096,7)\n",
        "AlexNet_model.eval()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "\n",
        "AlexNet_model.to(device)\n",
        "\n",
        "param_classifier1 = []\n",
        "param_classifier2 = []\n",
        "for idx, m in enumerate(AlexNet_model.modules()):\n",
        "  if idx == 18 or idx == 21:\n",
        "    print(idx, '->', m)\n",
        "    param_classifier1.append(m.weight)\n",
        "  if idx == 23:\n",
        "    print(idx, '->', m)\n",
        "    param_classifier2.append(m.weight)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD([\n",
        "      {'params': AlexNet_model.features.parameters()},\n",
        "      {'params': param_classifier1},\n",
        "      {'params': param_classifier2, 'lr': 0.01}], \n",
        "      lr=0.001, momentum=0.9)\n",
        "\n",
        "optimizer_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=12, gamma=0.1)\n",
        "\n",
        "AlexNet_model.train()\n",
        "print(\"Is the model in training mode?\",AlexNet_model.training)\n",
        "\n",
        "def train_model(model, trainingLoaderSet, testingLoaderSet, criterion, optimizer, lr_scheduler, num_epochs = 30):\n",
        "  '''\n",
        "  It will return:\n",
        "    1. Training and Testing loss record: running_Loss, val_Loss\n",
        "    2. Training and Testing accuracy record: running_Acc, val_Acc\n",
        "  '''\n",
        "  running_Loss = []\n",
        "  val_Loss = []\n",
        "  running_Acc = []\n",
        "  val_Acc = []\n",
        "\n",
        "  startTime = time.time()\n",
        "\n",
        "  startTime = time.time() # record the start time of training process\n",
        "  pbar_all = tqdm(total=num_epochs, desc=\"Total training progress\", ncols=700) # display the progress of training process\n",
        "\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    loss_train = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    loss_test = 0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    model.train() # Trun the mode into training state\n",
        "\n",
        "    # Training process\n",
        "    pbar = tqdm(total=sum([len(item) for item in trainingLoaderSet]), desc=\"Epoch %d training progress\"%(epoch), ncols=700) \n",
        "    for DatasetIndex, eachDataset in enumerate(trainingLoaderSet): # loop over the 8 sub-dataset\n",
        "      for i, data in enumerate(eachDataset, 0):\n",
        "        # send the input to GPU memory; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        \n",
        "        optimizer.zero_grad()  # zero the parameter gradients  \n",
        "        output = model(inputs) # forward propagation\n",
        "        loss = criterion(output, labels) # caculate the loss between output and ground truth \n",
        "        loss.backward() # backward propagation        \n",
        "        optimizer.step() # update the gradient to new gradients        \n",
        "        loss_train += loss.item() # Caculate the loss and the number of correct predicted results \n",
        "\n",
        "        # caculate the running loss and accuracy\n",
        "        model.eval() # turn the model into evaluation mode\n",
        "        with torch.no_grad(): # turn off the gradient descent process\n",
        "          output = model(inputs)\n",
        "          _, predicted = torch.max(output.data, 1)\n",
        "          correct_train += (predicted == labels).sum().item()\n",
        "          total_train += labels.size(0)\n",
        "\n",
        "        model.train()\n",
        "        pbar.update(1)\n",
        "    \n",
        "    lr_scheduler.step()\n",
        "    \n",
        "    running_Loss.append([epoch, (loss_train / total_train)])\n",
        "    running_Acc.append([epoch, (correct_train / total_train)])\n",
        "    #pbar.close()\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    # Testing process, evaluate the model through the testing dataset\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      pbar = tqdm(total=sum([len(item) for item in testingLoaderSet]), desc=\"Epoch %d testing progress\"%(epoch), ncols=700) \n",
        "      for DatasetIndex, eachDataset_test in enumerate(testingLoaderSet):\n",
        "        for i, data in enumerate(eachDataset_test):\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels) \n",
        "          _, predicted = torch.max(outputs.data, 1)       \n",
        "          correct_test += (predicted == labels).sum().item()\n",
        "          total_test += labels.size(0)\n",
        "          loss_test += loss.item()\n",
        "\n",
        "          pbar.update(1)\n",
        "\n",
        "    val_Loss.append([epoch, (loss_test / total_test)])\n",
        "    val_Acc.append([epoch, (correct_test / total_test)])\n",
        "    #pbar.close()\n",
        "\n",
        "    print('Epoch %d  |  Running Loss: %.6f  |  Validation Loss: %.6f  |  Running Accuracy: %.3f%%  |  Validataion Accuracy: %.3f%%  |  ' \n",
        "       %(epoch, (loss_train / total_train), (loss_test / total_test), (100 * correct_train / total_train), (100 * correct_test / total_test)))    \n",
        "    print('Learning Rate:',end='')\n",
        "    for item in optimizer.param_groups:\n",
        "      print(' '+ str(item['lr']) + ',',end='')\n",
        "\n",
        "    pbar_all.update(1)\n",
        "  pbar_all.close()\n",
        "  \n",
        "  torch.save(model, '/content/drive/Shareddrives/Surgery Video Research Team/Code/EndoNetModel.pkl')\n",
        "  print(\"Train the model cost total %d hours %d minutes\"%((time.time() - startTime)/3600,(time.time() - startTime)%60))\n",
        "\n",
        "  return running_Loss, val_Loss, running_Acc, val_Acc\n",
        "\n",
        "running_Loss, val_Loss, running_Acc, val_Acc = train_model(AlexNet_model,\n",
        "                                trainingLoaderSet, valLoaderSet, \n",
        "                                criterion, optimizer, lr_scheduler = optimizer_scheduler, \n",
        "                                num_epochs = 30)\n",
        "\n",
        "print(running_Loss)\n",
        "print(val_Loss) \n",
        "print(running_Acc) \n",
        "print(val_Acc)\n",
        "plt.figure()\n",
        "plt.plot([item[0] for item in running_Acc], [item[1] for item in running_Acc], label='Training Accuracy')\n",
        "plt.plot([item[0] for item in val_Acc], [item[1] for item in val_Acc], label='Validation Accuracy')\n",
        "for x in range(0,30,5):  \n",
        "  y = running_Acc[x][1]\n",
        "  s = str(round(running_Acc[x][1],2))\n",
        "  plt.text(x-1, y, s, fontsize=10)\n",
        "plt.text(29-1, running_Acc[29][1], round(running_Acc[29][1],2), fontsize=10)\n",
        "for x in range(0,30,5):  \n",
        "  y = val_Acc[x][1]\n",
        "  s = str(round(val_Acc[x][1],2))\n",
        "  plt.text(x-1, y, s, fontsize=10)\n",
        "plt.text(29-1, val_Acc[29][1], round(val_Acc[29][1],2), fontsize=10)\n",
        "plt.xlabel(\"# Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Epoch vs Accuracy\")\n",
        "plt.savefig('EpochvsAcc.jpg')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot([item[0] for item in running_Loss], [item[1] for item in running_Loss], label = \"Training Loss\")\n",
        "plt.plot([item[0] for item in val_Loss], [item[1] for item in val_Loss], label = \"Validation Loss\")\n",
        "for x in range(0,30,5):  \n",
        "  y = running_Loss[x][1]\n",
        "  s = str(round(running_Loss[x][1],5))\n",
        "  plt.text(x-1, y+0.0005, s, fontsize=10)\n",
        "plt.text(29, running_Loss[29][1], round(running_Loss[29][1],5), fontsize=10)\n",
        "for x in range(0,30,5):  \n",
        "  y = val_Loss[x][1]\n",
        "  s = str(round(val_Loss[x][1],4))\n",
        "  plt.text(x-1, y+0.0005, s, fontsize=10)\n",
        "plt.text(29, val_Loss[29][1], round(val_Loss[29][1],4), fontsize=10)\n",
        "\n",
        "plt.xlabel(\"# Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Epoch vs Loss\")\n",
        "plt.savefig('EpochvsLoss.jpg')\n",
        "plt.show()\n",
        "\n",
        "AlexNet_model = torch.load(\"/content/drive/Shareddrives/Surgery Video Research Team/Code/EndoNetModel.pkl\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "\n",
        "AlexNet_model.to(device)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "predictedList = []\n",
        "startTime = time.time()\n",
        "\n",
        "AlexNet_model.eval()\n",
        "pbar = tqdm(total=sum([len(item) for item in testingLoaderSet]), desc=\"Testing progress\", ncols=700) \n",
        "with torch.no_grad():\n",
        "  for DatasetIndex, eachDataset in enumerate(testingLoaderSet): \n",
        "    for i, data in enumerate(eachDataset):\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs = AlexNet_model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      predictedList.append([predicted.tolist(), labels.tolist(), DatasetIndex])\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      pbar.update(1)\n",
        "pbar.close()\n",
        "\n",
        "print('Accuracy of the network on the testing dataset: %.2f %%' %(100 * correct / total))\n",
        "print(\"Test the model cost total %d minutes\"%((time.time() - startTime)/60))\n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plotConfusionMatrix(y_true, y_predicted):\n",
        "  confmat = confusion_matrix(y_true, y_predicted)\n",
        "  plt.figure(figsize=(10,8))\n",
        "  sn.heatmap(confmat, annot=True)\n",
        "  plt.xlabel(\"Predicted phase\")\n",
        "  plt.ylabel(\"True phase\")\n",
        "  plt.show()\n",
        "\n",
        "phaseTrue = []\n",
        "phasePredicted = []\n",
        "\n",
        "for index, item in enumerate(predictedList):\n",
        "  phaseTrue += item[1]\n",
        "  phasePredicted += item[0]\n",
        "\n",
        "plotConfusionMatrix(phaseTrue, phasePredicted)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
        "\n",
        "\n",
        "print(\"Accuracy: %.2f%%\"%(accuracy_score(phaseTrue, phasePredicted)*100))\n",
        "print(\"Recll: %.2f%%\"%(recall_score(phaseTrue, phasePredicted, average='weighted')*100))\n",
        "print(\"F1 score: %.2f%%\"%(f1_score(phaseTrue, phasePredicted, average='weighted')*100))\n",
        "print(\"Precision score: %.2f%%\"%(precision_score(phaseTrue, phasePredicted, average='weighted')*100))"
      ]
    }
  ]
}